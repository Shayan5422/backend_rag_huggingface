{
    "model_id": "timm/vit_base_patch16_224.augreg2_in21k_ft_in1k",
    "downloads": 457709,
    "tags": [
        "timm",
        "pytorch",
        "safetensors",
        "image-classification",
        "transformers",
        "dataset:imagenet-1k",
        "dataset:imagenet-21k",
        "arxiv:2106.10270",
        "arxiv:2010.11929",
        "license:apache-2.0",
        "region:us"
    ],
    "description": "--- tags: - image-classification - timm - transformers library_name: timm license: apache-2.0 datasets: - imagenet-1k - imagenet-21k --- # Model card for vit_base_patch16_224.augreg2_in21k_ft_in1k A Vision Transformer (ViT) image classification model. Trained on ImageNet-21k by paper authors and (re) fine-tuned on ImageNet-1k with additional augmentation and regularization by Ross Wightman. ## Model Details - **Model Type:** Image classification / feature backbone - **Model Stats:** - Params (M): 86.6 - GMACs: 16.9 - Activations (M): 16.5 - Image size: 224 x 224 - **Papers:** - How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers: - An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale: - **Dataset:** ImageNet-1k - **Pretrain Dataset:** ImageNet-21k - **Original:** ## Model Usage ### Image Classification ### Image Embeddings ## Model Comparison Explore the dataset and runtime metrics of this model in timm model results. ## Citation",
    "model_explanation_gemini": "Performs image classification using a Vision Transformer (ViT) architecture, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k with enhanced augmentation and regularization."
}