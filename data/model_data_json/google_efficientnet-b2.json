{
    "model_id": "google/efficientnet-b2",
    "downloads": 178472,
    "tags": [
        "transformers",
        "pytorch",
        "efficientnet",
        "image-classification",
        "vision",
        "dataset:imagenet-1k",
        "arxiv:1905.11946",
        "license:apache-2.0",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us"
    ],
    "description": "--- license: apache-2.0 tags: - vision - image-classification datasets: - imagenet-1k widget: - src: example_title: Tiger - src: example_title: Teapot - src: example_title: Palace --- # EfficientNet (b2 model) EfficientNet model trained on ImageNet-1k at resolution 260x260. It was introduced in the paper EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks by Mingxing Tan and Quoc V. Le, and first released in this repository. Disclaimer: The team releasing EfficientNet did not write a model card for this model so this model card has been written by the Hugging Face team. ## Model description EfficientNet is a mobile friendly pure convolutional model (ConvNet) that proposes a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. !model image ## Intended uses & limitations You can use the raw model for image classification. See the model hub to look for fine-tuned versions on a task that interests you. ### How to use Here is how to use this model to classify an image of the COCO 2017 dataset into one of the 1,000 ImageNet classes: For more code examples, we refer to the documentation. ### BibTeX entry and citation info",
    "model_explanation_gemini": "Classifies images into 1,000 ImageNet categories using EfficientNet-b2 architecture trained at 260x260 resolution."
}