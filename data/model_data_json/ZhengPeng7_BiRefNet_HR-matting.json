{
    "model_id": "ZhengPeng7/BiRefNet_HR-matting",
    "downloads": 131064,
    "tags": [
        "birefnet",
        "safetensors",
        "background-removal",
        "mask-generation",
        "Dichotomous Image Segmentation",
        "Camouflaged Object Detection",
        "Salient Object Detection",
        "pytorch_model_hub_mixin",
        "model_hub_mixin",
        "image-segmentation",
        "custom_code",
        "arxiv:2401.03407",
        "license:mit",
        "endpoints_compatible",
        "region:us"
    ],
    "description": "--- library_name: birefnet tags: - background-removal - mask-generation - Dichotomous Image Segmentation - Camouflaged Object Detection - Salient Object Detection - pytorch_model_hub_mixin - model_hub_mixin repo_url: pipeline_tag: image-segmentation license: mit --- > This BiRefNet was trained with images in for higher resolution image matting with transparency. ### Performance: > All tested in FP16 mode. | Dataset | Method | Resolution | maxFm | wFmeasure | MAE | Smeasure | meanEm | HCE | maxEm | meanFm | adpEm | adpFm | mBA | maxBIoU | meanBIoU | | :------: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | :------: | | TE-AM-2k | **BiRefNet_HR-matting**-epoch_135 | 2048x2048 | .974 | .997 | .989 | .002 | .998 | .987 | .988 | .961 | .981 | .000 | .879 | .965 | .893 | | TE-P3M-500-NP | **BiRefNet_HR-matting**-epoch_135 | 2048x2048 | .980 | .996 | .989 | .002 | .997 | .987 | .989 | .880 | .900 | .000 | .853 | .947 | .897 | | TE-AM-2k | **BiRefNet-matting**-epoch_100 | 1024x1024 | .973 | .996 | .990 | .003 | .997 | .987 | .989 | .987 | .991 | .000 | .846 | .952 | .890 | | TE-P3M-500-NP | **BiRefNet-matting**-epoch_100 | 1024x1024 | .979 | .996 | .990 | .003 | .997 | .987 | .989 | .928 | .951 | .000 | .830 | .940 | .891 | | TE-AM-2k | **BiRefNet-matting**-epoch_100 | 2048x2048 | .971 | .996 | .990 | .003 | .997 | .987 | .988 | .990 | .992 | .000 | .838 | .941 | .891 | | TE-P3M-500-NP | **BiRefNet-matting**-epoch_100 | 2048x2048 | .978 | .995 | .990 | .003 | .996 | .987 | .989 | .955 | .971 | .000 | .818 | .931 | .891 | <h1 align=\"center\">Bilateral Reference for High-Resolution Dichotomous Image Segmentation</h1> <div align='center'> <a href=' target='_blank'><strong>Peng Zheng</strong></a><sup> 1,4,5,6</sup>,&thinsp; <a href=' target='_blank'><strong>Dehong Gao</strong></a><sup> 2</sup>,&thinsp; <a href=' target='_blank'><strong>Deng-Ping Fan</strong></a><sup> 1*</sup>,&thinsp; <a href=' target='_blank'><strong>Li Liu</strong></a><sup> 3</sup>,&thinsp; <a href=' target='_blank'><strong>Jorma Laaksonen</strong></a><sup> 4</sup>,&thinsp; <a href=' target='_blank'><strong>Wanli Ouyang</strong></a><sup> 5</sup>,&thinsp; <a href=' target='_blank'><strong>Nicu Sebe</strong></a><sup> 6</sup> </div> <div align='center'> <sup>1 </sup>Nankai University&ensp; <sup>2 </sup>Northwestern Polytechnical University&ensp; <sup>3 </sup>National University of Defense Technology&ensp; <sup>4 </sup>Aalto University&ensp; <sup>5 </sup>Shanghai AI Laboratory&ensp; <sup>6 </sup>University of Trento&ensp; </div> <div align=\"center\" style=\"display: flex; justify-content: center; flex-wrap: wrap;\"> <a href=' src=' <a href=' src=' <a href=' src=' <a href=' src=' <a href=' src=' <a href='LICENSE'><img src=' <a href=' src=' <a href=' src=' <a href=' src=' <a href=' src=' </div> | *DIS-Sample_1* | *DIS-Sample_2* | | :------------------------------: | :-------------------------------: | | <img src=\" /> | <img src=\" /> | This repo is the official implementation of \"**Bilateral Reference for High-Resolution Dichotomous Image Segmentation**\" (___CAAI AIR 2024___). Visit our GitHub repo: for more details -- **codes**, **docs**, and **model zoo**! ## How to use ### 0. Install Packages: ### 1. Load BiRefNet: #### Use codes + weights from HuggingFace > Only use the weights on HuggingFace -- Pro: No need to download BiRefNet codes manually; Con: Codes on HuggingFace might not be latest version (I'll try to keep them always latest). #### Use codes from GitHub + weights from HuggingFace > Only use the weights on HuggingFace -- Pro: codes are always latest; Con: Need to clone the BiRefNet repo from my GitHub. #### Use codes from GitHub + weights from local space > Only use the weights and codes both locally. #### Use the loaded BiRefNet for inference ### 2. Use inference endpoint locally: > You may need to click the *deploy* and set up the endpoint by yourself, which would make some costs. > This BiRefNet for standard dichotomous image segmentation (DIS) is trained on **DIS-TR** and validated on **DIS-TEs and DIS-VD**. ## This repo holds the official model weights of \"<ins>Bilateral Reference for High-Resolution Dichotomous Image Segmentation</ins>\" (_CAAI AIR 2024_). This repo contains the weights of BiRefNet proposed in our paper, which has achieved the SOTA performance on three tasks (DIS, HRSOD, and COD). Go to my GitHub page for BiRefNet codes and the latest updates: :) #### Try our online demos for inference: + Online **Image Inference** on Colab: ![Open In Colab]( + **Online Inference with GUI on Hugging Face** with adjustable resolutions: ![Hugging Face Spaces]( + **Inference and evaluation** of your given weights: ![Open In Colab]( <img src=\" /> ## Acknowledgement: + Many thanks to @freepik for their generous support on GPU resources for training this model! ## Citation",
    "model_explanation_gemini": "Performs high-resolution image matting with transparency for tasks like background removal, mask generation, and dichotomous image segmentation."
}