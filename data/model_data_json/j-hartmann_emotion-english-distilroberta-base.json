{
    "model_id": "j-hartmann/emotion-english-distilroberta-base",
    "downloads": 1458009,
    "tags": [
        "transformers",
        "pytorch",
        "tf",
        "roberta",
        "text-classification",
        "distilroberta",
        "sentiment",
        "emotion",
        "twitter",
        "reddit",
        "en",
        "arxiv:2210.00434",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us"
    ],
    "description": "--- language: \"en\" tags: - distilroberta - sentiment - emotion - twitter - reddit widget: - text: \"Oh wow. I didn't know that.\" - text: \"This movie always makes me cry..\" - text: \"Oh Happy Day\" --- # Emotion English DistilRoBERTa-base # Description ‚Ñπ With this model, you can classify emotions in English text data. The model was trained on 6 diverse datasets (see Appendix below) and predicts Ekman's 6 basic emotions, plus a neutral class: 1) anger ü§¨ 2) disgust ü§¢ 3) fear üò® 4) joy üòÄ 5) neutral üòê 6) sadness üò≠ 7) surprise üò≤ The model is a fine-tuned checkpoint of DistilRoBERTa-base. For a 'non-distilled' emotion model, please refer to the model card of the RoBERTa-large version. # Application üöÄ a) Run emotion model with 3 lines of code on single text example using Hugging Face's pipeline command on Google Colab: Run emotion model on multiple examples and full datasets (e.g., .csv files) on Google Colab: extends the popular EmotionLines dataset, EmotionLines itself is not included here. |Name|anger|disgust|fear|joy|neutral|sadness|surprise| |---|---|---|---|---|---|---|---| |Crowdflower (2016)|Yes|-|-|Yes|Yes|Yes|Yes| |Emotion Dataset, Elvis et al. (2018)|Yes|-|Yes|Yes|-|Yes|Yes| |GoEmotions, Demszky et al. (2020)|Yes|Yes|Yes|Yes|Yes|Yes|Yes| |ISEAR, Vikash (2018)|Yes|Yes|Yes|Yes|-|Yes|-| |MELD, Poria et al. (2019)|Yes|Yes|Yes|Yes|Yes|Yes|Yes| |SemEval-2018, EI-reg, Mohammad et al. (2018) |Yes|-|Yes|Yes|-|Yes|-| The model is trained on a balanced subset from the datasets listed above (2,811 observations per emotion, i.e., nearly 20k observations in total). 80% of this balanced subset is used for training and 20% for evaluation. The evaluation accuracy is 66% (vs. the random-chance baseline of 1/7 = 14%). # Scientific Applications üìñ Below you can find a list of papers using \"Emotion English DistilRoBERTa-base\". If you would like your paper to be added to the list, please send me an email. - Butt, S., Sharma, S., Sharma, R., Sidorov, G., & Gelbukh, A. (2022). What goes on inside rumour and non-rumour tweets and their reactions: A Psycholinguistic Analyses. Computers in Human Behavior, 107345. - Kuang, Z., Zong, S., Zhang, J., Chen, J., & Liu, H. (2022). Music-to-Text Synaesthesia: Generating Descriptive Text from Music Recordings. arXiv preprint arXiv:2210.00434. - Rozado, D., Hughes, R., & Halberstadt, J. (2022). Longitudinal analysis of sentiment and emotion in news media headlines using automated labelling with Transformer language models. Plos one, 17(10), e0276367.",
    "model_explanation_gemini": "Classifies English text into Ekman's 6 basic emotions (anger, disgust, fear, joy, sadness, surprise) plus neutral."
}