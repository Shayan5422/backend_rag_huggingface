{
    "model_id": "deepset/roberta-base-squad2",
    "downloads": 1675126,
    "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "rust",
        "safetensors",
        "roberta",
        "question-answering",
        "en",
        "dataset:squad_v2",
        "base_model:FacebookAI/roberta-base",
        "base_model:finetune:FacebookAI/roberta-base",
        "license:cc-by-4.0",
        "model-index",
        "endpoints_compatible",
        "region:us"
    ],
    "description": "--- language: en license: cc-by-4.0 datasets: - squad_v2 model-index: - name: deepset/roberta-base-squad2 results: - task: type: question-answering name: Question Answering dataset: name: squad_v2 type: squad_v2 config: squad_v2 split: validation metrics: - type: exact_match value: 79.9309 name: Exact Match verified: true verifyToken: >- eyJhbGciOiJFZERTQSIsInR5cCI6IkpXVCJ9.eyJoYXNoIjoiMDhhNjg5YzNiZGQ1YTIyYTAwZGUwOWEzZTRiYzdjM2QzYjA3ZTUxNDM1NjE1MTUyMjE1MGY1YzEzMjRjYzVjYiIsInZlcnNpb24iOjF9.EH5JJo8EEFwU7osPz3s7qanw_tigeCFhCXjSfyN0Y1nWVnSfulSxIk_DbAEI5iE80V4EKLyp5-mYFodWvL2KDA - type: f1 value: 82.9501 name: F1 verified: true verifyToken: >- eyJhbGciOiJFZERTQSIsInR5cCI6IkpXVCJ9.eyJoYXNoIjoiMjk5ZDYwOGQyNjNkMWI0OTE4YzRmOTlkY2JjNjQ0YTZkNTMzMzNkYTA0MDFmNmI3NjA3NjNlMjhiMDQ2ZjJjNSIsInZlcnNpb24iOjF9.DDm0LNTkdLbGsue58bg1aH_s67KfbcmkvL-6ZiI2s8IoxhHJMSf29H_uV2YLyevwx900t-MwTVOW3qfFnMMEAQ - type: total value: 11869 name: total verified: true verifyToken: >- eyJhbGciOiJFZERTQSIsInR5cCI6IkpXVCJ9.eyJoYXNoIjoiMGFkMmI2ODM0NmY5NGNkNmUxYWViOWYxZDNkY2EzYWFmOWI4N2VhYzY5MGEzMTVhOTU4Zjc4YWViOGNjOWJjMCIsInZlcnNpb24iOjF9.fexrU1icJK5_MiifBtZWkeUvpmFISqBLDXSQJ8E6UnrRof-7cU0s4tX_dIsauHWtUpIHMPZCf5dlMWQKXZuAAA - task: type: question-answering name: Question Answering dataset: name: squad type: squad config: plain_text split: validation metrics: - type: exact_match value: 85.289 name: Exact Match - type: f1 value: 91.841 name: F1 - task: type: question-answering name: Question Answering dataset: name: adversarial_qa type: adversarial_qa config: adversarialQA split: validation metrics: - type: exact_match value: 29.5 name: Exact Match - type: f1 value: 40.367 name: F1 - task: type: question-answering name: Question Answering dataset: name: squad_adversarial type: squad_adversarial config: AddOneSent split: validation metrics: - type: exact_match value: 78.567 name: Exact Match - type: f1 value: 84.469 name: F1 - task: type: question-answering name: Question Answering dataset: name: squadshifts amazon type: squadshifts config: amazon split: test metrics: - type: exact_match value: 69.924 name: Exact Match - type: f1 value: 83.284 name: F1 - task: type: question-answering name: Question Answering dataset: name: squadshifts new_wiki type: squadshifts config: new_wiki split: test metrics: - type: exact_match value: 81.204 name: Exact Match - type: f1 value: 90.595 name: F1 - task: type: question-answering name: Question Answering dataset: name: squadshifts nyt type: squadshifts config: nyt split: test metrics: - type: exact_match value: 82.931 name: Exact Match - type: f1 value: 90.756 name: F1 - task: type: question-answering name: Question Answering dataset: name: squadshifts reddit type: squadshifts config: reddit split: test metrics: - type: exact_match value: 71.55 name: Exact Match - type: f1 value: 82.939 name: F1 base_model: - FacebookAI/roberta-base --- # roberta-base for Extractive QA This is the roberta-base model, fine-tuned using the SQuAD2.0 dataset. It's been trained on question-answer pairs, including unanswerable questions, for the task of Extractive Question Answering. We have also released a distilled version of this model called deepset/tinyroberta-squad2. It has a comparable prediction quality and runs at twice the speed of deepset/roberta-base-squad2. ## Overview **Language model:** roberta-base **Language:** English **Downstream-task:** Extractive QA **Training data:** SQuAD 2.0 **Eval data:** SQuAD 2.0 **Code:** See an example extractive QA pipeline built with Haystack **Infrastructure**: 4x Tesla v100 ## Hyperparameters ## Usage ### In Haystack Haystack is an AI orchestration framework to build customizable, production-ready LLM applications. You can use this model in Haystack to do extractive question answering on documents. To load and run the model with Haystack: For a complete example with an extractive question answering pipeline that scales over many documents, check out the corresponding Haystack tutorial. ### In Transformers ## Performance Evaluated on the SQuAD 2.0 dev set with the official eval script. ## Authors **Branden Chan:** branden.chan@deepset.ai **Timo MÃ¶ller:** timo.moeller@deepset.ai **Malte Pietsch:** malte.pietsch@deepset.ai **Tanay Soni:** tanay.soni@deepset.ai ## About us <div class=\"grid lg:grid-cols-2 gap-x-4 gap-y-3\"> <div class=\"w-full h-40 object-cover mb-2 rounded-lg flex items-center justify-center\"> <img alt=\"\" src=\" class=\"w-40\"/> </div> <div class=\"w-full h-40 object-cover mb-2 rounded-lg flex items-center justify-center\"> <img alt=\"\" src=\" class=\"w-40\"/> </div> </div> deepset is the company behind the production-ready open-source AI framework Haystack. Some of our other work: - Distilled roberta-base-squad2 (aka \"tinyroberta-squad2\") - German BERT, GermanQuAD and GermanDPR, German embedding model - deepset Cloud - deepset Studio ## Get in touch and join the Haystack community <p>For more info on Haystack, visit our <strong><a href=\" repo and <strong><a href=\" We also have a <strong><a class=\"h-7\" href=\" community open to everyone!</a></strong></p> Twitter | LinkedIn | Discord | GitHub Discussions | Website | YouTube By the way: we're hiring!",
    "model_explanation_gemini": "Answers questions by extracting relevant text segments from given documents, trained on the SQuAD2.0 dataset including unanswerable questions."
}