{
    "model_id": "biu-nlp/f-coref",
    "downloads": 217419,
    "tags": [
        "transformers",
        "pytorch",
        "roberta",
        "fast",
        "coreference-resolution",
        "en",
        "dataset:multi_news",
        "dataset:ontonotes",
        "arxiv:2209.04280",
        "arxiv:2205.12644",
        "arxiv:1907.10529",
        "arxiv:2101.00434",
        "arxiv:2109.04127",
        "license:mit",
        "model-index",
        "endpoints_compatible",
        "region:us"
    ],
    "description": "--- language: - en tags: - fast - coreference-resolution license: mit datasets: - multi_news - ontonotes metrics: - CoNLL task_categories: - coreference-resolution model-index: - name: biu-nlp/f-coref results: - task: type: coreference-resolution name: coreference-resolution dataset: name: ontonotes type: coreference metrics: - name: Avg. F1 type: CoNLL value: 78.5 --- ## F-Coref: Fast, Accurate and Easy to Use Coreference Resolution F-Coref allows to process 2.8K OntoNotes documents in 25 seconds on a V100 GPU (compared to 6 minutes for the LingMess model, and to 12 minutes of the popular AllenNLP coreference model) with only a modest drop in accuracy. The fast speed is achieved through a combination of distillation of a compact model from the LingMess model, and an efficient batching implementation using a technique we call leftover Please check the official repository for more details and updates. #### Experiments | Model | Runtime | Memory | |-----------------------|---------|---------| | Joshi et al. (2020) | 12:06 | 27.4 | | Otmazgin et al. (2022) | 06:43 | 4.6 | | + Batching | 06:00 | 6.6 | | Kirstain et al. (2021) | 04:37 | 4.4 | | Dobrovolskii (2021) | 03:49 | 3.5 | | F-Coref | 00:45 | 3.3 | | + Batching | 00:35 | 4.5 | | + Leftovers batching | 00:25 | 4.0 | The inference time(Min:Sec) and memory(GiB) for each model on 2.8K documents. Average of 3 runs. Hardware, NVIDIA Tesla V100 SXM2. ### Citation F-coref: Fast, Accurate and Easy to Use Coreference Resolution (Otmazgin et al., AACL-IJCNLP 2022)",
    "model_explanation_gemini": "F-Coref is a fast and efficient coreference resolution model optimized for speed and performance, achieving high accuracy while processing documents significantly quicker than comparable models."
}