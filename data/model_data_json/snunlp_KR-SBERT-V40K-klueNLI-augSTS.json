{
    "model_id": "snunlp/KR-SBERT-V40K-klueNLI-augSTS",
    "downloads": 392865,
    "tags": [
        "sentence-transformers",
        "pytorch",
        "bert",
        "feature-extraction",
        "sentence-similarity",
        "transformers",
        "ko",
        "autotrain_compatible",
        "text-embeddings-inference",
        "endpoints_compatible",
        "region:us"
    ],
    "description": "--- pipeline_tag: sentence-similarity tags: - sentence-transformers - feature-extraction - sentence-similarity - transformers language: - ko widget: - source_sentence: \"그 식당은 파리를 날린다\" sentences: - \"그 식당에는 손님이 없다\" - \"그 식당에서는 드론을 날린다\" - \"파리가 식당에 날아다닌다\" example_title: \"Restaurant\" - source_sentence: \"잠이 옵니다\" sentences: - \"잠이 안 옵니다\" - \"졸음이 옵니다\" - \"기차가 옵니다\" example_title: \"Sleepy\" --- # snunlp/KR-SBERT-V40K-klueNLI-augSTS This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search. <!--- Describe your model here --> ## Usage (Sentence-Transformers) Using this model becomes easy when you have sentence-transformers installed: Then you can use the model like this: ## Usage (HuggingFace Transformers) Without sentence-transformers, you can use the model like this: First, you pass your input through the transformer model, then you have to apply the right pooling-operation on-top of the contextualized word embeddings. ## Evaluation Results <!--- Describe how your model was evaluated --> For an automated evaluation of this model, see the *Sentence Embeddings Benchmark*: ## Full Model Architecture ## Application for document classification Tutorial in Google Colab: |Model|Accuracy| |-|-| |KR-SBERT-Medium-NLI-STS|0.8400| |KR-SBERT-V40K-NLI-STS|0.8400| |KR-SBERT-V40K-NLI-augSTS|0.8511| |KR-SBERT-V40K-klueNLI-augSTS|**0.8628**| ## Citation",
    "model_explanation_gemini": "Computes semantic similarity between Korean sentences by mapping them to 768-dimensional vectors for tasks like clustering or semantic search."
}