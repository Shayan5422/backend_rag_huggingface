{
    "model_id": "THUDM/chatglm3-6b",
    "downloads": 153439,
    "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "chatglm",
        "glm",
        "thudm",
        "custom_code",
        "zh",
        "en",
        "arxiv:2103.10360",
        "arxiv:2210.02414",
        "arxiv:2406.12793",
        "endpoints_compatible",
        "region:us"
    ],
    "description": "--- language: - zh - en tags: - glm - chatglm - thudm --- # ChatGLM3-6B <p align=\"center\"> 💻 <a href=\" target=\"_blank\">Github Repo</a> • 🐦 <a href=\" target=\"_blank\">Twitter</a> • 📃 <a href=\" target=\"_blank\">[GLM@ACL 22]</a> <a href=\" target=\"_blank\">[GitHub]</a> • 📃 <a href=\" target=\"_blank\">[GLM-130B@ICLR 23]</a> <a href=\" target=\"_blank\">[GitHub]</a> <br> </p> <p align=\"center\"> 👋 Join our <a href=\" target=\"_blank\">Slack</a> and <a href=\" target=\"_blank\">WeChat</a> </p> <p align=\"center\"> 📍Experience the larger-scale ChatGLM model at <a href=\" </p> ## GLM-4 开源模型 我们已经发布最新的 **GLM-4** 模型，该模型在多个指标上有了新的突破，您可以在以下两个渠道体验我们的最新模型。 + GLM-4 开源模型 我们已经开源了 GLM-4-9B 系列模型，在各项指标的测试上有明显提升，欢迎尝试。 ## 介绍 (Introduction) ChatGLM3-6B 是 ChatGLM 系列最新一代的开源模型，在保留了前两代模型对话流畅、部署门槛低等众多优秀特性的基础上，ChatGLM3-6B 引入了如下特性： 1. **更强大的基础模型：** ChatGLM3-6B 的基础模型 ChatGLM3-6B-Base 采用了更多样的训练数据、更充分的训练步数和更合理的训练策略。在语义、数学、推理、代码、知识等不同角度的数据集上测评显示，ChatGLM3-6B-Base 具有在 10B 以下的预训练模型中最强的性能。 2. **更完整的功能支持：** ChatGLM3-6B 采用了全新设计的 Prompt 格式，除正常的多轮对话外。同时原生支持工具调用（Function Call）、代码执行（Code Interpreter）和 Agent 任务等复杂场景。 3. **更全面的开源序列：** 除了对话模型 ChatGLM3-6B 外，还开源了基础模型 ChatGLM-6B-Base、长文本对话模型 ChatGLM3-6B-32K。以上所有权重对学术研究**完全开放**，在填写问卷进行登记后**亦允许免费商业使用**。 ChatGLM3-6B is the latest open-source model in the ChatGLM series. While retaining many excellent features such as smooth dialogue and low deployment threshold from the previous two generations, ChatGLM3-6B introduces the following features: 1. **More Powerful Base Model:** The base model of ChatGLM3-6B, ChatGLM3-6B-Base, employs a more diverse training dataset, more sufficient training steps, and a more reasonable training strategy. Evaluations on datasets such as semantics, mathematics, reasoning, code, knowledge, etc., show that ChatGLM3-6B-Base has the strongest performance among pre-trained models under 10B. 2. **More Comprehensive Function Support:** ChatGLM3-6B adopts a newly designed Prompt format, in addition to the normal multi-turn dialogue. It also natively supports function call, code interpreter, and complex scenarios such as agent tasks. 3. **More Comprehensive Open-source Series:** In addition to the dialogue model ChatGLM3-6B, the base model ChatGLM-6B-Base and the long-text dialogue model ChatGLM3-6B-32K are also open-sourced. All the weights are **fully open** for academic research, and after completing the questionnaire registration, they are also **allowed for free commercial use**. ## 软件依赖 (Dependencies) ## 代码调用 (Code Usage) 可以通过如下代码调用 ChatGLM3-6B 模型来生成对话： You can generate dialogue by invoking the ChatGLM3-6B model with the following code: 关于更多的使用说明，包括如何运行命令行和网页版本的 DEMO，以及使用模型量化以节省显存，请参考我们的 Github Repo。 For more instructions, including how to run CLI and web demos, and model quantization, please refer to our Github Repo. ## 协议 (License) 本仓库的代码依照 Apache-2.0 协议开源，ChatGLM3-6B 模型的权重的使用则需要遵循 Model License。 The code in this repository is open-sourced under the Apache-2.0 license, while the use of the ChatGLM3-6B model weights needs to comply with the Model License. ## 引用 (Citation) 如果你觉得我们的工作有帮助的话，请考虑引用下列论文。 If you find our work helpful, please consider citing the following paper.",
    "model_explanation_gemini": "ChatGLM3-6B is an open-source multilingual (Chinese/English) conversational AI model optimized for smooth dialogue, supporting complex tasks like function calls, code execution, and agent workflows while offering strong performance in semantics, reasoning, and knowledge tasks."
}