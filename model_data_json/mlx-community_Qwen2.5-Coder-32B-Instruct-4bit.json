{
    "model_id": "mlx-community/Qwen2.5-Coder-32B-Instruct-4bit",
    "downloads": 74138,
    "tags": [
        "transformers",
        "safetensors",
        "qwen2",
        "text-generation",
        "code",
        "codeqwen",
        "chat",
        "qwen",
        "qwen-coder",
        "mlx",
        "conversational",
        "en",
        "base_model:Qwen/Qwen2.5-Coder-32B-Instruct",
        "base_model:quantized:Qwen/Qwen2.5-Coder-32B-Instruct",
        "license:apache-2.0",
        "autotrain_compatible",
        "text-generation-inference",
        "endpoints_compatible",
        "4-bit",
        "region:us"
    ],
    "description": "--- base_model: Qwen/Qwen2.5-Coder-32B-Instruct language: - en library_name: transformers license: apache-2.0 license_link: pipeline_tag: text-generation tags: - code - codeqwen - chat - qwen - qwen-coder - mlx --- # mlx-community/Qwen2.5-Coder-32B-Instruct-4bit The Model mlx-community/Qwen2.5-Coder-32B-Instruct-4bit was converted to MLX format from Qwen/Qwen2.5-Coder-32B-Instruct using mlx-lm version **0.19.3**. ## Use with mlx"
}