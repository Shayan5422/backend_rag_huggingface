{
    "model_id": "zhiqiulin/clip-flant5-xxl",
    "downloads": 366546,
    "tags": [
        "transformers",
        "pytorch",
        "t5",
        "text2text-generation",
        "en",
        "arxiv:2404.01291",
        "base_model:google/flan-t5-xxl",
        "base_model:finetune:google/flan-t5-xxl",
        "license:apache-2.0",
        "autotrain_compatible",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
    ],
    "description": "--- license: apache-2.0 language: - en base_model: - google/flan-t5-xxl --- # CLIP-FlanT5-XXL (VQAScore) <!-- Provide a quick summary of what the model is/does. --> This model is a fine-tuned version of google/flan-t5-xxl designed for image-text retrieval tasks, as presented in the VQAScore paper. ### Model Description <!-- Provide a longer summary of what this model is. --> - **Developed by:** Zhiqiu Lin and collaborators - **Model type:** Vision-Language Generative Model - **License:** Apache-2.0 - **Finetuned from model:** google/flan-t5-xxl ### Model Sources [optional] <!-- Provide the basic links for the model. --> - **Repository:** - **Paper:** - **Demo:**",
    "model_explanation_gemini": "Fine-tuned version of google/flan-t5-xxl for image-text retrieval tasks, as presented in the VQAScore paper."
}