{
    "model_id": "naver/splade-v3",
    "downloads": 91658,
    "tags": [
        "transformers",
        "pytorch",
        "bert",
        "fill-mask",
        "splade",
        "en",
        "arxiv:2403.06789",
        "license:cc-by-nc-sa-4.0",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us"
    ],
    "description": "--- license: cc-by-nc-sa-4.0 language: - en tags: - splade --- ## SPLADE-v3 #### SPLADE-v3 is the latest series of SPLADE models. This checkpoint corresponds to a model that starts from SPLADE++SelfDistil (), and is trained with a mix of KL-Div and MarginMSE, with 8 negatives per query sampled from SPLADE++SelfDistil. We used the original MS MARCO collection **without the titles**. For more details, see our arXiv companion book: To use SPLADE, please visit our GitHub repository: ## Performance | | MRR@10 (MS MARCO dev) | avg nDCG@10 (BEIR-13) | | --- | --- | --- | | | 40.2 | 51.7 | ## Citation If you use our checkpoint, please cite our work:",
    "model_explanation_gemini": "SPLADE-v3 is a retrieval model trained on MS MARCO data without titles, optimized for document search using KL-Div and MarginMSE losses with 8 negatives per query."
}