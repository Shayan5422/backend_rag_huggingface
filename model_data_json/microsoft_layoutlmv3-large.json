{
    "model_id": "microsoft/layoutlmv3-large",
    "downloads": 106598,
    "tags": [
        "transformers",
        "pytorch",
        "tf",
        "layoutlmv3",
        "en",
        "arxiv:2204.08387",
        "license:cc-by-nc-sa-4.0",
        "endpoints_compatible",
        "region:us"
    ],
    "description": "--- language: en license: cc-by-nc-sa-4.0 --- # LayoutLMv3 Microsoft Document AI | GitHub ## Model description LayoutLMv3 is a pre-trained multimodal Transformer for Document AI with unified text and image masking. The simple unified architecture and training objectives make LayoutLMv3 a general-purpose pre-trained model. For example, LayoutLMv3 can be fine-tuned for both text-centric tasks, including form understanding, receipt understanding, and document visual question answering, and image-centric tasks such as document image classification and document layout analysis. LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, Furu Wei, Preprint 2022. ## Citation If you find LayoutLM useful in your research, please cite the following paper: ## License The content of this project itself is licensed under the Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0). Portions of the source code are based on the transformers project. Microsoft Open Source Code of Conduct",
    "model_explanation_gemini": "LayoutLMv3 is a multimodal Transformer model pre-trained for Document AI tasks, capable of fine-tuning for both text-centric (e.g., form understanding) and image-centric (e.g., document layout analysis) applications."
}