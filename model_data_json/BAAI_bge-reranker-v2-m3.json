{
    "model_id": "BAAI/bge-reranker-v2-m3",
    "downloads": 1891532,
    "tags": [
        "sentence-transformers",
        "safetensors",
        "xlm-roberta",
        "text-classification",
        "transformers",
        "text-embeddings-inference",
        "multilingual",
        "arxiv:2312.15503",
        "arxiv:2402.03216",
        "license:apache-2.0",
        "region:us"
    ],
    "description": "--- license: apache-2.0 pipeline_tag: text-classification tags: - transformers - sentence-transformers - text-embeddings-inference language: - multilingual --- # Reranker **More details please refer to our Github: FlagEmbedding.** - Model List - Usage - Fine-tuning - Evaluation - Citation Different from embedding model, reranker uses question and document as input and directly output similarity instead of embedding. You can get a relevance score by inputting query and passage to the reranker. And the score can be mapped to a float value in [0,1] by sigmoid function. ## Model List | Model | Base model | Language | layerwise | feature | |:--------------------------------------------------------------------------|:--------:|:-----------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------:| | BAAI/bge-reranker-base | xlm-roberta-base | Chinese and English | - | Lightweight reranker model, easy to deploy, with fast inference. | | BAAI/bge-reranker-large | xlm-roberta-large | Chinese and English | - | Lightweight reranker model, easy to deploy, with fast inference. | | BAAI/bge-reranker-v2-m3 | bge-m3 | Multilingual | - | Lightweight reranker model, possesses strong multilingual capabilities, easy to deploy, with fast inference. | | BAAI/bge-reranker-v2-gemma | gemma-2b | Multilingual | - | Suitable for multilingual contexts, performs well in both English proficiency and multilingual capabilities. | | BAAI/bge-reranker-v2-minicpm-layerwise | MiniCPM-2B-dpo-bf16 | Multilingual | 8-40 | Suitable for multilingual contexts, performs well in both English and Chinese proficiency, allows freedom to select layers for output, facilitating accelerated inference. | You can select the model according your senario and resource. - For **multilingual**, utilize BAAI/bge-reranker-v2-m3 and BAAI/bge-reranker-v2-gemma - For **Chinese or English**, utilize BAAI/bge-reranker-v2-m3 and BAAI/bge-reranker-v2-minicpm-layerwise. - For **efficiency**, utilize BAAI/bge-reranker-v2-m3 and the low layer of BAAI/bge-reranker-v2-minicpm-layerwise. - For better performance, recommand BAAI/bge-reranker-v2-minicpm-layerwise and BAAI/bge-reranker-v2-gemma ## Usage ### Using FlagEmbedding #### For normal reranker (bge-reranker-base / bge-reranker-large / bge-reranker-v2-m3 ) Get relevance scores (higher scores indicate more relevance): #### For LLM-based reranker #### For LLM-based layerwise reranker ### Using Huggingface transformers #### For normal reranker (bge-reranker-base / bge-reranker-large / bge-reranker-v2-m3 ) Get relevance scores (higher scores indicate more relevance): #### For LLM-based reranker #### For LLM-based layerwise reranker ## Fine-tune ### Data Format Train data should be a json file, where each line is a dict like this: is the query, and is a list of positive texts, is a list of negative texts, indicates the relationship between query and texts. If you have no negative texts for a query, you can random sample some from the entire corpus as the negatives. See toy_finetune_data.jsonl for a toy data file. ### Train You can fine-tune the reranker with the following code: **For llm-based reranker** **For llm-based layerwise reranker** Our rerankers are initialized from google/gemma-2b (for llm-based reranker) and openbmb/MiniCPM-2B-dpo-bf16 (for llm-based layerwise reranker), and we train it on a mixture of multilingual datasets: - bge-m3-data - quora train data - fever train data ## Evaluation - llama-index. !image-20240317193909373 - BEIR. rereank the top 100 results from bge-en-v1.5 large. !image-20240317174633333 rereank the top 100 results from e5 mistral 7b instruct. !image-20240317172949713 - CMTEB-retrieval. It rereank the top 100 results from bge-zh-v1.5 large. !image-20240317173026235 - miracl (multi-language). It rereank the top 100 results from bge-m3. !image-20240317173117639 ## Citation If you find this repository useful, please consider giving a star and citation",
    "model_explanation_gemini": "Computes relevance scores between queries and documents in multiple languages to rank passages by similarity."
}