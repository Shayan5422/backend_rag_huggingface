{
    "model_id": "anthracite-org/magnum-v2-12b-gguf",
    "downloads": 99075,
    "tags": [
        "gguf",
        "chat",
        "text-generation",
        "en",
        "fr",
        "de",
        "es",
        "it",
        "pt",
        "ru",
        "zh",
        "ja",
        "base_model:anthracite-org/magnum-v2-12b",
        "base_model:quantized:anthracite-org/magnum-v2-12b",
        "license:apache-2.0",
        "endpoints_compatible",
        "region:us",
        "imatrix",
        "conversational"
    ],
    "description": "--- license: apache-2.0 language: - en - fr - de - es - it - pt - ru - zh - ja pipeline_tag: text-generation quantized_by: anthracite-org base_model: anthracite-org/magnum-v2-12b tags: - chat --- ## This repo contains GGUF quants of the model. If you need the original weights, please find them here. This is the fourth in a series of models designed to replicate the prose quality of the Claude 3 models, specifically Sonnet and Opus. This model is fine-tuned on top of Mistral-Nemo-Base-2407. !image/png ## Prompting Model has been Instruct tuned with the ChatML formatting. A typical input would look like this: ## Credits - Stheno dataset (filtered) - kalomaze/Opus_Instruct_25k - Nopm/Opus_WritingStruct - Gryphe/Sonnet3.5-SlimOrcaDedupCleaned (A ~16k rows subset) - kalomaze/Opus_Instruct_3k This model has been a team effort, and the credits goes to all members of Anthracite. ## Training The training was done for 2 epochs. We used 8x NVIDIA H100 Tensor Core GPUs for the full-parameter fine-tuning of the model. <img src=\" alt=\"Built with Axolotl\" width=\"200\" height=\"32\"/> ## Safety ...",
    "model_explanation_gemini": "Fine-tuned for high-quality text generation in multiple languages, replicating Claude 3's prose style using ChatML formatting."
}