{
    "model_id": "mlx-community/DeepSeek-R1-Distill-Qwen-32B-4bit",
    "downloads": 74600,
    "tags": [
        "transformers",
        "safetensors",
        "qwen2",
        "text-generation",
        "mlx",
        "conversational",
        "base_model:deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
        "base_model:quantized:deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
        "autotrain_compatible",
        "text-generation-inference",
        "endpoints_compatible",
        "4-bit",
        "region:us"
    ],
    "description": "--- library_name: transformers base_model: deepseek-ai/DeepSeek-R1-Distill-Qwen-32B tags: - mlx --- # mlx-community/DeepSeek-R1-Distill-Qwen-32B-4bit The Model mlx-community/DeepSeek-R1-Distill-Qwen-32B-4bit was converted to MLX format from deepseek-ai/DeepSeek-R1-Distill-Qwen-32B using mlx-lm version **0.20.2**. ## Use with mlx"
}