{
    "model_id": "unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit",
    "downloads": 92426,
    "tags": [
        "transformers",
        "safetensors",
        "mistral",
        "text-generation",
        "unsloth",
        "conversational",
        "en",
        "license:apache-2.0",
        "autotrain_compatible",
        "text-generation-inference",
        "endpoints_compatible",
        "4-bit",
        "bitsandbytes",
        "region:us"
    ],
    "description": "--- language: - en library_name: transformers license: apache-2.0 tags: - mistral - unsloth - transformers --- # Finetune Mistral, Gemma, Llama 2-5x faster with 70% less memory via Unsloth! We have a free Google Colab Tesla T4 notebook for Mistral Nemo 12b here: <img src=\" width=\"200\"/> <img src=\" width=\"200\"/> <img src=\" width=\"200\"/> ## ✨ Finetune for Free All notebooks are **beginner friendly**! Add your dataset, click \"Run All\", and you'll get a 2x faster finetuned model which can be exported to GGUF, vLLM or uploaded to Hugging Face. | Unsloth supports | Free Notebooks | Performance | Memory use | |-----------------|--------------------------------------------------------------------------------------------------------------------------|-------------|----------| | **Llama-3 8b** | ▶️ Start on Colab | 2.4x faster | 58% less | | **Gemma 7b** | ▶️ Start on Colab | 2.4x faster | 58% less | | **Mistral 7b** | ▶️ Start on Colab | 2.2x faster | 62% less | | **Llama-2 7b** | ▶️ Start on Colab | 2.2x faster | 43% less | | **TinyLlama** | ▶️ Start on Colab | 3.9x faster | 74% less | | **CodeLlama 34b** A100 | ▶️ Start on Colab | 1.9x faster | 27% less | | **Mistral 7b** 1xT4 | ▶️ Start on Kaggle | 5x faster\\* | 62% less | | **DPO - Zephyr** | ▶️ Start on Colab | 1.9x faster | 19% less | - This conversational notebook is useful for ShareGPT ChatML / Vicuna templates. - This text completion notebook is for raw text. This DPO notebook replicates Zephyr. - \\* Kaggle has 2x T4s, but we use 1. Due to overhead, 1x T4 is 5x faster.",
    "model_explanation_gemini": "Optimizes Mistral, Gemma, and Llama 2 models for faster fine-tuning with reduced memory usage using Unsloth, offering beginner-friendly notebooks for efficient model adaptation."
}