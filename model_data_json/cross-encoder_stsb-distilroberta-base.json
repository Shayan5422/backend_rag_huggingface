{
    "model_id": "cross-encoder/stsb-distilroberta-base",
    "downloads": 262724,
    "tags": [
        "sentence-transformers",
        "pytorch",
        "jax",
        "onnx",
        "safetensors",
        "openvino",
        "roberta",
        "text-classification",
        "transformers",
        "text-ranking",
        "en",
        "dataset:sentence-transformers/stsb",
        "base_model:distilbert/distilroberta-base",
        "base_model:quantized:distilbert/distilroberta-base",
        "license:apache-2.0",
        "region:us"
    ],
    "description": "--- license: apache-2.0 datasets: - sentence-transformers/stsb language: - en base_model: - distilbert/distilroberta-base pipeline_tag: text-ranking library_name: sentence-transformers tags: - transformers --- # Cross-Encoder for Semantic Textual Similarity This model was trained using SentenceTransformers Cross-Encoder class. ## Training Data This model was trained on the STS benchmark dataset. The model will predict a score between 0 and 1 how for the semantic similarity of two sentences. ## Usage and Performance Pre-trained models can be used like this: The model will predict scores for the pairs and . You can use this model also without sentence_transformers and by just using Transformers `` class",
    "model_explanation_gemini": "Predicts semantic similarity scores (0-1) between two English sentences using a cross-encoder trained on the STS benchmark dataset."
}